{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This example trains a classification probe in order to investigate the information present in the residual stream.",
   "id": "1c56e09bd3a869a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "aca8cb2c26644049"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:12:19.408205Z",
     "start_time": "2025-06-12T16:12:05.049351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "\n",
    "llm = HookedTransformer.from_pretrained(\"EleutherAI/pythia-2.8b-deduped-v0\")"
   ],
   "id": "92f3607e5c743e61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UKGC\\PycharmProjects\\TokenFinder\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-2.8b-deduped-v0 into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Look for activation heads that move information from nouns to the word 'it'",
   "id": "67da57608027113a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:12:19.443492Z",
     "start_time": "2025-06-12T16:12:19.439204Z"
    }
   },
   "cell_type": "code",
   "source": "nouns = [\"cat\",\"dog\",\"car\",\"tree\",\"house\",\"book\",\"river\",\"mountain\",\"computer\",\"phone\",\"table\",\"chair\",\"window\",\"door\",\"city\",\"road\",\"flower\",\"bird\",\"fish\",\"apple\",\"banana\",\"train\",\"plane\",\"boat\",\"shoe\",\"shirt\",\"hat\",\"cup\",\"plate\",\"fork\",\"spoon\",\"knife\",\"bed\",\"pillow\",\"blanket\",\"clock\",\"watch\",\"bag\",\"box\",\"key\",\"pen\",\"pencil\",\"paper\",\"bottle\",\"glass\",\"lamp\",\"mirror\",\"painting\",\"camera\",\"television\",\"radio\",\"guitar\",\"piano\",\"drum\",\"violin\",\"ball\",\"bat\",\"glove\",\"bike\",\"bus\",\"truck\",\"bridge\",\"tower\",\"statue\",\"park\",\"garden\",\"forest\",\"desert\",\"island\",\"beach\",\"lake\",\"ocean\",\"cloud\",\"star\",\"moon\",\"sun\",\"planet\",\"ring\",\"necklace\",\"note\",\"wallet\",\"coin\",\"ticket\",\"passport\",\"map\",\"letter\",\"envelope\",\"stamp\",\"magazine\",\"bean\",\"calendar\",\"notebook\",\"folder\",\"file\",\"mouse\",\"board\",\"monitor\"]",
   "id": "b865bf55485bada1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:12:19.653831Z",
     "start_time": "2025-06-12T16:12:19.648204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for noun in nouns:\n",
    "    tokens = llm.tokenizer.tokenize(f\"There is a {noun}\", add_special_tokens=True)\n",
    "    if len(tokens) > 5:\n",
    "        print(noun)\n",
    "        print(tokens)"
   ],
   "id": "26769410e788921c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:12:19.664808Z",
     "start_time": "2025-06-12T16:12:19.662648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_templates = [\n",
    "    \"I saw a _noun_, it was big.\",\n",
    "    \"Look at that _noun_, I saw it yesterday too.\",\n",
    "    \"A _noun_ is coming, it will be here soon.\",\n",
    "    \"After the _noun_ arrived, it looked at it.\"\n",
    "]"
   ],
   "id": "349381ad60bc12e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:12:26.694232Z",
     "start_time": "2025-06-12T16:12:26.690746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_data = [\n",
    "    {\"sentence\": sentence.replace(\"_noun_\", noun), \"noun\": noun} for noun in nouns for sentence in sentence_templates\n",
    "]\n",
    "\n",
    "print(f\"{len(sentence_data)} sentences\")"
   ],
   "id": "9b132123b73b6cd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 sentences\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:15:01.305643Z",
     "start_time": "2025-06-12T16:14:17.237147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from llm_token_finder import ActivationAnalyzer, TokenFinder, TokenDisplayer\n",
    "from llm_token_finder.activation_analyser import AttentionHead\n",
    "import random\n",
    "\n",
    "\n",
    "all_it_heads = []\n",
    "\n",
    "# Get random sample to find attention heads\n",
    "sample_data = random.sample(sentence_data, 50)\n",
    "\n",
    "for item in tqdm(sample_data):\n",
    "    token_finder = TokenFinder.create_from_tokenizer(item[\"sentence\"], llm.tokenizer)\n",
    "    noun_token = token_finder.find_first(item[\"noun\"], allow_space_prefix=True)\n",
    "    it_token = token_finder.find_first(\"it\", allow_space_prefix=True)\n",
    "    activation_analyzer = ActivationAnalyzer.from_forward_pass(llm, item[\"sentence\"])\n",
    "    item_heads = activation_analyzer.find_heads_where_query_looks_at_value(it_token, noun_token, ignore_bos=True)\n",
    "    all_it_heads.append(item_heads)\n",
    "\n",
    "it_heads = AttentionHead.intersection(all_it_heads)\n",
    "\n",
    "print(f\"Found {len(it_heads)} attention heads moving information from noun tokens to 'it' tokens: {it_heads}\")"
   ],
   "id": "2df584802d024d51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:44<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 attention heads moving information from noun tokens to 'it' tokens: [5.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate activation dataset for attention head output",
   "id": "fab29ed10ec233d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "wWe have found attention heads that move information from nouns to 'it'. It seems likely that these heads are moving information about the meaning of the noun, but the above doesn't confirm that, only that they are moving *something*; they could be moving some other information. In order to investigate what is being moved, we will train a classifier on the output of one of the attention heads.",
   "id": "87637643a59dc30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:15:11.766360Z",
     "start_time": "2025-06-12T16:15:11.764217Z"
    }
   },
   "cell_type": "code",
   "source": "head = it_heads[0]",
   "id": "bcd40f21e668a508",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:15:14.293283Z",
     "start_time": "2025-06-12T16:15:14.288048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Generator\n",
    "from activation_probing.activation_dataset_generator import ActivationDatasetGenerator, ActivationGeneratorInput\n",
    "\n",
    "\n",
    "# Our input generator function must yield ActivationGenerationInput objects that will be fed through the LLM to create our head-output dataset\n",
    "\n",
    "def input_generator() -> Generator[ActivationGeneratorInput, None, None]:\n",
    "    for item in sentence_data:\n",
    "        token_finder = TokenFinder.create_from_tokenizer(item[\"sentence\"], llm.tokenizer)\n",
    "        it_token = token_finder.find_first(\"it\", allow_space_prefix=True)\n",
    "        yield ActivationGeneratorInput(\n",
    "            text=item[\"sentence\"],\n",
    "            token_position=it_token.index,\n",
    "            label_class_index=nouns.index(item[\"noun\"])\n",
    "        )"
   ],
   "id": "52bee6432d7da6b0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:15:16.147758Z",
     "start_time": "2025-06-12T16:15:16.144738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation_dataset_generator = ActivationDatasetGenerator.create_attention_head_output_generator(\n",
    "    llm,\n",
    "    input_generator,\n",
    "    class_labels=nouns,\n",
    "    head=head,\n",
    "    meta_data={\"experiment\": \"noun-it test\"}\n",
    ")"
   ],
   "id": "6c28990674fb504c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:26:13.274131Z",
     "start_time": "2025-06-12T16:15:16.948901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from activation_probing.activation_dataset import ActivationDataset\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# ActivationDatasetGenerator saves the dataset to a file, which can be loaded later. For this example, we'll just save and load immediately from a temporary file\n",
    "\n",
    "with tempfile.TemporaryFile(mode=\"r+\", encoding=\"utf-8\") as file:\n",
    "    activation_dataset_generator.generate_and_save_to(file)\n",
    "    activation_dataset = ActivationDataset.load_from_file(file, device=llm.cfg.device)"
   ],
   "id": "4dd21d556861ffc6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:27:42.997997Z",
     "start_time": "2025-06-12T16:27:42.994584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The activation dataset is a subclass of a PyTorch TensorDataset that saves extra metadata, including custom metadata we passed to the generator, about the data\n",
    "\n",
    "print(f\"Size of activation dataset: {len(activation_dataset)}\")\n",
    "\n",
    "print(f\"Metadata: {activation_dataset.meta_data}\")"
   ],
   "id": "6b4927689b76b701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of activation dataset: 388\n",
      "Metadata: {'layer': 5, 'head': 0, 'class_labels': ['cat', 'dog', 'car', 'tree', 'house', 'book', 'river', 'mountain', 'computer', 'phone', 'table', 'chair', 'window', 'door', 'city', 'road', 'flower', 'bird', 'fish', 'apple', 'banana', 'train', 'plane', 'boat', 'shoe', 'shirt', 'hat', 'cup', 'plate', 'fork', 'spoon', 'knife', 'bed', 'pillow', 'blanket', 'clock', 'watch', 'bag', 'box', 'key', 'pen', 'pencil', 'paper', 'bottle', 'glass', 'lamp', 'mirror', 'painting', 'camera', 'television', 'radio', 'guitar', 'piano', 'drum', 'violin', 'ball', 'bat', 'glove', 'bike', 'bus', 'truck', 'bridge', 'tower', 'statue', 'park', 'garden', 'forest', 'desert', 'island', 'beach', 'lake', 'ocean', 'cloud', 'star', 'moon', 'sun', 'planet', 'ring', 'necklace', 'note', 'wallet', 'coin', 'ticket', 'passport', 'map', 'letter', 'envelope', 'stamp', 'magazine', 'bean', 'calendar', 'notebook', 'folder', 'file', 'mouse', 'board', 'monitor'], 'llm': 'pythia-2.8b-deduped-v0', 'timestamp': '2025-06-12T16:15:16Z', 'experiment': 'noun-it test'}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use head-output activation dataset to train a classification probe",
   "id": "afb27b6418b846cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:27:44.820576Z",
     "start_time": "2025-06-12T16:27:43.839887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probe, _, _, history = activation_dataset.train_probe(num_epochs=50, learning_rate=0.01, return_history=True, device=\"cpu\")\n",
    "\n",
    "print(f\"Probe training accuracy: {history[\"training_accuracy\"][-1]}; test accuracy {history['testing_accuracy'][-1]}\")"
   ],
   "id": "4d6a6decfa428d09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe training accuracy: 1.0; test accuracy 0.9358974358974359\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The probe has high accuracy, meaning it has learnt to classify nouns from the output of this attention head **at the 'it' token position**.",
   "id": "54451f897cf4ed8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:32:58.959117Z",
     "start_time": "2025-06-12T16:32:56.344955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show an example that isn't in the dataset\n",
    "\n",
    "test_sentence = \"There is a big, square box in the corner of the room; I wonder what is in it.\"\n",
    "\n",
    "token_finder = TokenFinder.create_from_tokenizer(test_sentence, llm.tokenizer)\n",
    "\n",
    "noun_token = token_finder.find_first(\"box\", allow_space_prefix=True)\n",
    "it_token = token_finder.find_first(\"it\", allow_space_prefix=True)\n",
    "\n",
    "_, cache = llm.run_with_cache(llm.tokenizer.encode(test_sentence, add_special_tokens=True, return_tensors=\"pt\"), names_filter=lambda x: x == f\"blocks.{head.layer}.attn.hook_result\")"
   ],
   "id": "f2a5e2282a1477e0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:36:22.925982Z",
     "start_time": "2025-06-12T16:36:22.922820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "head_output_at_it_position = cache[f\"blocks.{head.layer}.attn.hook_result\"][0][it_token.index][head.head]\n",
    "\n",
    "probe_logits = probe.forward(head_output_at_it_position)\n",
    "probe_predicted_index = torch.argmax(probe_logits)\n",
    "probe_prediction = nouns[probe_predicted_index]\n",
    "\n",
    "print(f\"Probe prediction (should be 'box'): {probe_prediction}\")"
   ],
   "id": "88f1b3796c4b0d5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe prediction (should be 'box'): box\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
