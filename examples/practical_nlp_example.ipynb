{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This example finds attention heads that move information from adjectives to the corresponding nouns in a sentence. It uses the `ActivationAnalyzer` class to find heads that match a certain criteria.",
   "id": "1d537a25fa3aa3eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "7c559bbc42ac6698"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:24:25.819515Z",
     "start_time": "2025-05-12T17:24:07.351393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "\n",
    "llm = HookedTransformer.from_pretrained(\"EleutherAI/pythia-2.8b-deduped-v0\")"
   ],
   "id": "68280d02917badb2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UKGC\\PycharmProjects\\TokenFinder\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-2.8b-deduped-v0 into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:24:26.098640Z",
     "start_time": "2025-05-12T17:24:26.091643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"The quick, brown fox jumps over the lazy dog.\"\n",
    "\n",
    "input_tokens = llm.tokenizer.tokenize(text, add_special_tokens=True)\n",
    "input_token_ids = llm.tokenizer.encode(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "print(input_tokens)\n",
    "print(input_token_ids)"
   ],
   "id": "d17ffa61b685065a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'The', 'Ġquick', ',', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '.']\n",
      "tensor([[    0,   510,  3158,    13,  8516, 30013, 27287,   689,   253, 22658,\n",
      "          4370,    15]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:24:27.137664Z",
     "start_time": "2025-05-12T17:24:26.175149Z"
    }
   },
   "cell_type": "code",
   "source": "_, activation_cache = llm.run_with_cache(input_token_ids)",
   "id": "9cd6b05488fa31a1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find noun-adjective pairs",
   "id": "b6c55287ea795aff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llm_inspect import Token\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Noun:\n",
    "    noun_token: Token\n",
    "    adjective_tokens: list[Token]"
   ],
   "id": "33b20e7747d46553"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llm_inspect import TokenFinder, AttentionHeadFinder\n",
    "\n",
    "\n",
    "token_finder = TokenFinder.create_from_tokenizer(text, llm.tokenizer)\n",
    "activation_analyzer = AttentionHeadFinder.create_from_tokenizer(llm.tokenizer, input_tokens, activation_cache)"
   ],
   "id": "4bc4339bcfa61fe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fox = Noun(\n",
    "    noun_token=token_finder.find_first(\"fox\", allow_space_prefix=True),\n",
    "    adjective_tokens=[\n",
    "        token_finder.find_first(\"quick\", allow_space_prefix=True),\n",
    "        token_finder.find_first(\"brown\", allow_space_prefix=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "dog = Noun(\n",
    "    noun_token=token_finder.find_first(\"dog\", allow_space_prefix=True),\n",
    "    adjective_tokens=[\n",
    "        token_finder.find_first(\"lazy\", allow_space_prefix=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "nouns = [fox, dog]\n",
    "\n",
    "print(fox)\n",
    "print(dog)"
   ],
   "id": "a97b3ae6f3baf4db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Find heads that move information from adjectives to nouns",
   "id": "796c5a4ffb7c5a06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:24:36.297619Z",
     "start_time": "2025-05-12T17:24:36.279346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import Tensor\n",
    "from jaxtyping import Float\n",
    "\n",
    "\n",
    "def criteria(attention: Float[Tensor, \"q v\"]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns true if the maximum attention scores for each noun is the corresponding adjectives\n",
    "    \"\"\"\n",
    "    for noun in nouns:\n",
    "        noun_attention_scores = attention[noun.noun_token.index]\n",
    "        top_attention_score_indexes = noun_attention_scores.topk(len(noun.adjective_tokens)).indices\n",
    "        for adjective_token in noun.adjective_tokens:\n",
    "            if adjective_token.index not in top_attention_score_indexes:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "noun_advective_heads = activation_analyzer.find_heads_matching_criteria(criteria)\n",
    "\n",
    "print(f\"Found {len(noun_advective_heads)} head(s) that move information from adjectives to nouns\")"
   ],
   "id": "7cdacdaf010feea0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 head(s) that move information from adjectives to nouns\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualise",
   "id": "ce93680507673c67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llm_inspect import TokenDisplayer\n",
    "\n",
    "\n",
    "token_displayer = TokenDisplayer.create_for_tokenizer(llm.tokenizer)"
   ],
   "id": "c13771f0b6359314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Head {noun_advective_heads[0]}:\")\n",
    "\n",
    "token_displayer.html_for_token_attention(\n",
    "    input_tokens,\n",
    "    activation_cache,\n",
    "    noun_advective_heads[0],\n",
    ")"
   ],
   "id": "a858df07546a3da7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
